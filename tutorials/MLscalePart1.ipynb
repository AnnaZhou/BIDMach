{
 "metadata": {
  "name": "",
  "signature": "sha256:22f45353690173a2577bc2e2fbafc6d7451ad1be2a2f1701e04b27c0f3f9110f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Machine Learning at Scale, Part III"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import BIDMat.{CMat,CSMat,DMat,Dict,IDict,Image,FMat,FND,GDMat,GMat,GIMat,GSDMat,GSMat,HMat,IMat,Mat,SMat,SBMat,SDMat}\n",
      "import BIDMat.MatFunctions._\n",
      "import BIDMat.SciFunctions._\n",
      "import BIDMat.Solvers._\n",
      "import BIDMat.Plotting._\n",
      "import BIDMach.Learner\n",
      "import BIDMach.models.{FM,GLM,KMeans,KMeansw,LDA,LDAgibbs,Model,NMF,RandomForest,SFA}\n",
      "import BIDMach.datasources.{DataSource,MatDS,FilesDS,SFilesDS}\n",
      "import BIDMach.mixins.{CosineSim,Perplexity,Top,L1Regularizer,L2Regularizer}\n",
      "import BIDMach.updaters.{ADAGrad,Batch,BatchNorm,IncMult,IncNorm,Telescoping}\n",
      "import BIDMach.causal.{IPTW}\n",
      "\n",
      "Mat.checkMKL\n",
      "Mat.checkCUDA\n",
      "if (Mat.hasCUDA > 0) GPUmem"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "KMeans clustering at scale"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Training models with data that fits in memory is very limiting. But minibatch learners can easily work with data directly from disk. \n",
      "\n",
      "We'll use the MNIST data set, which has 8 million images (about 17 GB). The dataset has been partition into groups of 100k images (using the unix split command) and saved in compressed lz4 files. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val mdir = \"../data/MNIST8M/parts/\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The files we need are named \"alls00.fmat.lz4\", \"alls01.fmat.lz4\" etc. We can create a learner using a pattern for accessing these files:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val (mm, opts) = KMeans.learner(mdir+\"alls%02d.fmat.lz4\",1024)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The string \"%02d\" is a C/Scala format string that expands into a two-digit ASCII number to help with the enumeration.\n",
      "\n",
      "There are several new options that can tailor a files datasource, but we'll mostly use the defaults. One thing we will do is define the last file to use for training (number 70). This leaves us with some held-out files to use for testing. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "opts.nend = 70"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Tuning Options"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following options are the important ones for tuning. For KMeans, batchSize has no effect on accracy since the algorithm uses all the data instances to perform an update. So you're free to tune it for best speed. Generally larger is better, as long as you dont use too much GPU ram. \n",
      "\n",
      "npasses is the number of passes over the dataset. Larger is typically better, but the model may overfit at some point. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "opts.batchSize = 20000\n",
      "opts.npasses = 4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You invoke the learner the same way as before. You can change the options above after each run to optimize performance. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mm.train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now lets extract the model as a Floating-point matrix. We included the category features for clustering to make sure that each cluster is a subset of images for one digit. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val modelmat = FMat(mm.modelmat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we build a 30 x 10 array of images to view the first 300 cluster centers as images."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val nx = 30\n",
      "val ny = 10\n",
      "val im = zeros(28,28)\n",
      "val allim = zeros(28*nx,28*ny)\n",
      "for (i<-0 until nx) {\n",
      "    for (j<-0 until ny) {\n",
      "        val slice = modelmat(i+nx*j,10->794)\n",
      "        im(?) = slice(?)\n",
      "        allim((28*i)->(28*(i+1)), (28*j)->(28*(j+1))) = im\n",
      "    }\n",
      "}\n",
      "Image.show(allim kron ones(2,2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll predict using the closest cluster (or 1-NN if you like). First we read some data directly. We could also try to do evaluation directly from disk, but this would usually be overkill."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val test = loadFMat(mdir+\"alls70.fmat.lz4\")\n",
      "val testdata = test.copy\n",
      "testdata(0->10,?) = 0\n",
      "val preds = izeros(1, test.ncols)\n",
      "1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we define a predictor from the just-computed model and the testdata, with the preds matrix to catch the predictions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val (pp, popts) = KMeans.predictor(mm.model, testdata, preds, 1024)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets run the predictor"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pp.predict "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The <code>preds</code> matrix now contains the numbers of the best-matching cluster centers. We still need to look up the category label for each one. We also need to look up the category for each of the test inputs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val (vmax, predcat) = maxi2(modelmat(preds,0->10).t)   // Lookup the cat for the matching cluster\n",
      "val (wmax, truecat) = maxi2(test(0->10,?))             // Reference cats for test items\n",
      "val inds = predcat.t \\ truecat.t                       // Concatenate them into a two-column matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From the actual and predicted categories, we can compute a confusion matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val conf = accum(inds, 1f, 10, 10)  // accumulate the (estimate,exact) ids into a matrix\n",
      "conf ~ conf / sum(conf)             // normalize"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image.show((conf * 250f) \u2297 ones(64,64))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Its useful to isolate the correct classification rate by digit, which is:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val dacc = getdiag(conf).t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can take the mean of the diagonal accuracies to get an overall accuracy for this model. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean(dacc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run the experiment again with a larger number of clusters (3000, then 30000). You should reduce the batchSize option to 20000 to avoid memory problems.\n",
      "\n",
      "Include the training time output by the call to <code>nn.train</code> but not the evaluation time (the evaluation code above is not using the GPU). Rerun and fill out the table below: \n",
      "\n",
      "<table>\n",
      "<tr>\n",
      "<th>KMeans Clusters</th>\n",
      "<th>Training time</th>\n",
      "<th>Avg. gflops</th>\n",
      "<th>Accuracy</th>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>300</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>3000</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td>30000</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "<td>...</td>\n",
      "</tr>\n",
      "</table>"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}